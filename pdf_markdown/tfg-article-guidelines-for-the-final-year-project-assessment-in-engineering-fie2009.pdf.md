Session M2J 978-1-4244-4714-5/09/$25.00 ©2009 IEEE October 18 - 21, 2009, San
Antonio, TX 39th ASEE/IEEE Frontiers in Education Conference M2J-1 Guidelines
For The Final Year Project Assessment In Engineering Elena Valderrama, Mercè
Rullán, Fermín Sánchez, Jordi Pons, Claudi Mans, Francesc Giné, Laureà
Jiménez, Enric Peig Elena.Valderrama@uab.cat, Mercedes.Rullan@uab.cat,
fermin@ac.upc.edu, Jordi.Pons@uab.cat, cmans@ub.edu, sisco@diei.udl.cat,
Laureano.Jimenez@urv.cat, enric.peig@upf.edu Abstract - This paper presents an
efficient and objective procedure for the outcome-based assessment of
engineering final year projects (FYP). The procedure, consisting of 6 steps,
can easily be customized for different engineering curricula. A User Guide has
been developed to help institutions create their own FYP assessment system.
The guide includes the assessment procedure and aids for its implementation.
Particularly, a set of FYP-oriented observable descriptors for Tuning outcomes
was defined. The end-products of the proposed assessment procedure are a set
of assessment reports that the evaluator agent/s must fulfil per milestone,
marking the level reached by the student at every descriptor (0: unacceptable,
1: minimum acceptable, 2: good, 3: excellent). These marks are then gathered
together in an overall assessment sheet showing, for every learning outcome,
the evolution along the assessment milestones of the level reached by the
student at any descriptor. This sheet is a very powerful tool for setting the
final mark. All assessment agents use the same list of descriptors and the
same levels of acquisition, thus improving the consistency, traceability and
global quality of the assessment process. Index Terms – Assessment, Assessment
reports, Final year project, Learning outcomes. INTRODUCTION Engineering
curricula include the development and assessment of a final year project
(FYP). This FYP represents the culmination of the student learning process,
where he/she must put into use their previously learned engineering and
personal skills. The FYP is a complex event, and its assessment has a major
influence on decisions regarding the student’s readiness to graduate. In our
country (Spain), FYP students are assessed in most schools on the basis of a
final written report of the work done plus a public defense before an academic
jury composed of several experienced professors. Unfortunately, this approach
presents serious drawbacks: • Assessment has to mandatory shift to an outcome-
based approach to come into line with education and accreditation processes
[2],[3],[7]. • Assessment via a unique final milestone clashes directly with
the formative purpose of assessment. • Assessment is highly dependent on the
subjective criteria of academic jury. In December 2007, the AQU1 and the
MICINN2 launched a program for the development of a User Guide for the
outcome-based assessment of engineering FYP. Six universities3 from Catalonia
took on the task of developing this User Guide. A survey of the results of
that project is reported here. THE USER GUIDE The User Guide developed is
aimed at the academic authorities that have to define Syllabuses for FYP, and
provides them with a strategy for making an assessment of the same. It
contains a series of guidelines to help each Faculty or College to produce its
own procedure for assessing FYP. The User Guide proposes a process based on 6
stages that Faculties and Colleges must follow to define their own procedure
of assessing FYP: 1\. Definition of (i) the learning outcomes associated with
the FYP and (ii) a set of objective descriptors for each of them; 2\.
Definition of (i) the moments (milestones) of assessment, (ii) the specific
assessment actions that must be performed at each milestone and (iii) the
agents that will carry out the assessment; 3\. Assignation of descriptors to
each assessment action; 4\. Definition of the levels of compliance with each
descriptor, clearly and objectively establishing the level of competence that
the student must demonstrate that he/she possesses; 1 Agency for the Quality
of the Catalan University System. 2 Spanish Ministry of Science and Innovation
3 Autonoma University of Barcelona (UAB), Technical University of Catalonia
(UPC), University of Barcelona (UB), Lleida University (UdL), Rovira i Virgili
University (URV) and Pompeu Fabra University (UPF). Session M2J
978-1-4244-4714-5/09/$25.00 ©2009 IEEE October 18 - 21, 2009, San Antonio, TX
39th ASEE/IEEE Frontiers in Education Conference M2J-2 5\. Drafting of
assessment reports that the assessment agents must complete and 6\. Definition
of the marking criteria to be used to assign the final mark for the FYP on the
basis of the results reflected in the assessment report. Figure 1 shows the
described procedure in graphic form. FIGURE 1 PROCEDURE PROPOSED FOR THE
DEFINITION OF THE FYP ASSESSMENT PROCESS. I. Definition of skills and
descriptors The first step in the process consists of establishing what skills
the students must show they possess on completing their FYP. The specific
(technical) skills are very different depending on the specific studies, but
the transversal (generic) skills of any engineer are probably very similar,
regardless of their speciality. To assist with the definition of the
transversal skills, a survey was prepared and conducted of a sample group of
professors, who were asked to select, from a set of 28 transversal skills as
defined by the Tuning project [4], the ones that they felt should be
prioritized when assessing FYP. 135 valid responses were received, 108 from
Spanish academics and 27 from the rest of the European Community. This text is
too short to allow us space to show the final priority suggested for all the
skills but, as an example, table 1 shows the 5 skills that received the
highest scores. The full results of the survey can be found in [1]. In order
to be able to evaluate these skills, there is a need to define a set of
objective descriptors that make it possible to evaluate the level of
acquisition of the skill by the student. For each skill, a file was created
that (i) describes the skill from the point of view of the FYP, (ii) defines
descriptors for its assessment, and (iii) establishes the level that students
must show they have acquired for each descriptor. The file suggests at which
assessment milestone (see later) each descriptor should be assessed. TABLE I
MOST VOTED SKILLS FOR THEIR ASSESSMENT WITHIN THE FYP SKILL 1 Apply the
knowledge acquired to practice. 2 Oral and written communication in the native
tongue. 3 Conceive, design and implement projects using the inherent tools of
engineering. 4 Organization and planning. 5 Knowledge of the field of study.
Both the issue of surveys of skills and the definition of descriptors are
matters that have been dealt with on numerous occasions [5],[6], but what is
new about this study is that it is centred on the assessment of skills in the
context of FYP. II. Milestones, actions and assessment agents We propose the
establishment of at least three moments or “milestones” for the assessment of
FYP: (i) A first assessment that must be made during the first few weeks of
project, when the student has been working on their project for long enough to
develop a clear approach to the work, to have analysed the state-of-the-art of
the subject and its viability, and to have established a work plan; (ii) one
(or several) milestones for monitoring the project in the long term, better in
the second half of their development, when dysfunctions in the initial
approach can be detected but when there is still time to make the necessary
corrections and (iii) a final assessment milestone when the work is completed.
At each milestone, one or several assessment actions are proposed. The first
milestone includes two assessment actions: (i) the presentation of an initial
report and (ii) a presentation of this report to the student’s colleagues and
assessment agents. The intermediates milestone(s) includes a single action:
the presentation of a project progress report and an eventual interview with
the assessment agent if it is considered necessary. The final milestone
continues the traditional method of presenting a final report of the work and
its public presentation. TABLE II TIME SCALE, ACTIONS AND ASSESSMENT AGENT FOR
EVERY MILESTONE INITIAL MILESTONE: In the first ¼ of the FYP ACTIONS: 
Initial report  Presentation of the report AGENTS:  Tutor  Colleagues 
Professor or external expert PROGRESS MILESTONE: In the second 1/3 ACTIONS: 
Progress report AGENTS:  Tutor FINAL MILESTONE: At the end of the FYP
ACTIONS:  Report  Public defence before tribunal AGENTS:  Tribunal
(inclusion of an external expert recommended) Session M2J
978-1-4244-4714-5/09/$25.00 ©2009 IEEE October 18 - 21, 2009, San Antonio, TX
39th ASEE/IEEE Frontiers in Education Conference M2J-3 Finally, the agents
that should evaluate each of the actions are proposed. We consider that the
supervisor/tutor of the work should be involved in the assessment of all the
actions. It would also be recommendable to make peer evaluation at the first
milestone, and add the presence of external experts in the assessment of the
monitoring and final milestones. III. Assignation of descriptors to the
assessment actions Having reached this point, the descriptors defined for each
skill have to be distributed among the assessment actions so that the
evaluator knows what specific points need to be assessed at each moment. The
skills files produced include a recommended assignation of the descriptors at
each assessment milestone. Both the descriptors that appear in the skills
files and their assignation to each specific milestone are suggestions to make
things easier for the people in charge of centres. The final selection of
descriptors and their assignation to milestones and assessment actions should
be determined for each school. It is important to underline the need for
careful selection of the set of skills and descriptors to be assessed. We
advise against trying to evaluate more than 10 or 15 descriptors in a single
action, because this could lose sight of the student’s work perspective. Each
qualification should define which skills and via which descriptors each action
is to be assessed. The skills files [1] may be of assistance. IV. Level of
compliance with the descriptors Finding out what descriptors have to be
assessed is not enough: For the assessment to be objective and independent of
the evaluator there is a need to accurately define the level of compliance
that is demanded of the student in each. Four levels of compliance are
proposed for the descriptors: Level 1 corresponds to the minimum that the
student must be able to demonstrate, and for a level below that (level 0) it
is considered that the student does NOT comply with the descriptor. Level 2 is
that which is considered adequate for the FYP. Level 3 represents an excellent
level. Table 3, shows an example of the definition of the four levels of
compliance (level 0 is defined by exclusion) of the descriptors associated to
the skill of “Organisation and planning”. V. Assessment reports The assessment
reports that must be completed by the assessment agents are constructed after
assigning the descriptors to the assessment actions and defining the levels of
demand. Two types of report are proposed: Assessment Reports organised by
milestones, and the Overall Assessment Report, organized by skills. The
Assessment Reports constitute the final product of the assessment milestones;
they contain the set of descriptors to be assessed, a column for the mark
(from 0 to 3) and the levels of demand for each descriptor. These reports must
be public and their result should be provided to the student as quickly as
possible. TABLE III LEVEL OF COMPLIANCE WITH THE DESCRIPTORS FOR THE SKILL
“ORGANISATION AND PLANNING” DESCRIPTOR 1 : The student presents a diagram of
the project plan LEVEL 1: Score 1 if.. A plan of the time and resources
required is presented, even if the level of detail is superficial LEVEL 2:
Score 2 if.. The tasks, times and human and material resources are perfectly
identified and planned LEVEL 3: Score 2 if.. The level of detail by which
tasks, times and resources are specified is excellent DESCRIPTOR 2 : The
student is able to monitor the level of compliance with the initial plan,
identifying and analysing the deviations detected LEVEL 1: Score 1 if.. The
student is able at all times to identify the state of each task (behind
schedule, ahead of time, on time) LEVEL 2: Score 2 if.. Identifies
discrepancies from the established plan and proposes actions to resolve them.
LEVEL 3: Score 2 if.. Solutions proposed for any deviations are very coherent
and guarantee, as much as possible, compliance with the project DESCRIPTOR 3:
The student analyses the level of final compliance with the initial plan, the
causes of eventual deviations and the consequences of the same. LEVEL 1: Score
1 if.. A plan of the time and resources required is presented, even if the
level of detail is superficial LEVEL 2: Score 2 if.. The tasks, times and
human and material resources are perfectly identified and planned LEVEL 3:
Score 2 if.. The level of detail by which tasks, times and resources are
specified is excellent Thus, the assessment serves its educational role, by
indicating to the student what they will be assessed on and telling them after
each assessment action what their position is with respect to the expected
learning objectives and what aspects they need to improve in order to reach
them. Table 4 shows a (partial) example of the Assessment Report at the first
milestone. The compliance levels, as defined in table 3, should be included in
columns levelled as 1, 2 and 3. The results of these assessment actions are
used to automatically complement the Overall Assessment Report. This report
groups the set of assessments made, but now organised by skills, in such a way
that it is easy to visualise the student’s evolution over time. Table 5 shows
an example of this report. The overall assessment report is the one that makes
it possible to qualify the student, in view not only of the final level of
acquisition of the skills associated to the work, but also their evolution
over time. Working with a list of objective descriptors and objective criteria
for marking, which are scaled on different levels, homogenises qualifications
even when they originate from different assessment agents, increases the
traceability of the results, and hence, improves the quality of the process of
FYP assessing. VI. Qualification Finally, the Faculty or College must define
the criteria to be followed in order to provide the students with
qualifications. These criteria must define minimums, allowing for a certain
freedom in the analysis of the overall quality of the work done. Session M2J
978-1-4244-4714-5/09/$25.00 ©2009 IEEE October 18 - 21, 2009, San Antonio, TX
39th ASEE/IEEE Frontiers in Education Conference M2J-4 TABLE IV EXAMPLE OF THE
ASSESSMENT REPORT CORRESPONDING TO THE INITIAL MILESTONE INITIAL MILESTONE:
Assessment report Action: Initial report Descriptors Points (0-3) 1 2 3
Identify the fundamental parts of the project, drawing a diagram on a block
level that describes and displays the 1 Score 1 if … … Identify the knowledge
implied in resolving the project, both those belonging to the discipline and
from outside of it 2 Score 1 if … Evaluate the relative importance of each of
the parts of the project of the project and the knowledge implied. 2 Score 1
if … Etc…. … … Action: Presentation Descriptors Points (0- 3) Shows empathy
with the audience; looks at the audience; uses the right tone and volume of
voice,... 2 Score 1 if … Comments: Signed: (The assessment agent) One of the
outstanding aspects of the process described in this article is that, once the
assessment procedure has been defined, it is very easy to automate the
process. A web application can be made available in which the evaluators enter
their qualifications at each milestones and both the overall report and the
final qualification be automatically generated by following the criteria
defined, thus avoiding human error and guaranteeing the transparency of the
process. DISCUSSION There is a need to promote a change in the procedures for
assessing students in the context of the new student-focused teaching-learning
paradigm in all years, and especially in FYP. The current model for assessing
FYP, basically aimed to control if the student reaches the required level,
based on the assessment of technical content and a highly dependent of the
assessment agents, should give way for a model that highlights the training
aspect of the assessment, that values skills ahead of mere knowledge and in
which the assessment is as objective and retro-traceable as possible. The
objective of the User Guide that has been produced is to help Faculties and
Colleges to define procedures for assessing FYP that comply with these
requisites. The definition of objective descriptors and levels of compliance
with them that are to be used by all of the agents TABLE V EXAMPLE OVERALL
ASSESSMENT REPORT. M-1, M-2 AND M-3 CORRESPOND RESPECTIVELY TO THE INITIAL,
PROGRESS AND FINAL MILESTONES OVERALL ASSESSMENT REPORT SKILL 1: Ability to
conceive, design and implement projects using the inherent tools of
Engineering Descriptors M-1 M-2 M-3 Choose the most adequate tools and
methodologies to analyse, design and implement the project. 2 Analyse, design
and implement the project in accordance with the most adequate methodologies.
2 2 Find a solution to the proposed project that can be carried out
considering the inherent resources of Computer Engineering. 1 2 … etc.
Comments: SKILL 2: Capacity for analysis and synthesis. Descriptors M-1 M-2
M-3 Identify the fundamental parts of the project; drawing a diagram than on a
block level visually describes the relationships between them. 1 3 Evaluate
the results of the project, comparing them with similar results proceeding
from sources … etc. 3 … etc. Comments: SKILL 3: ... that intervene in the
analysis of students helps increase the independence of the qualification from
the different assessment agents, should give way for a model that highlights
the training aspect of the assessment, that values skills ahead of mere
knowledge and in which the assessment is as objective and retro-traceable as
possible. The objective of the User Guide that has been produced is to help
Faculties and Colleges to define procedures for assessing FYP that comply with
these requisites. The definition of objective descriptors and levels of
compliance with them that are to be used by all of the agents that intervene
in the analysis of students helps increase the independence of the
qualification from the different assessment agents, and at the same time
solves the problem of traceability. The question asked by students, “Why has
the tribunal marked my work with a “C”?” is answered by the overall assessment
report, which in turn is ratified by the assessment reports on each action, by
the definition of the levels of compliance with the descriptors and by the
actual definitions of the same. Session M2J 978-1-4244-4714-5/09/$25.00 ©2009
IEEE October 18 - 21, 2009, San Antonio, TX 39th ASEE/IEEE Frontiers in
Education Conference M2J-5 Similarly, the publication of assessment reports
has a direct effect on the educational aspect of the assessment. Here it is
important to highlight the importance of making the assessment model public
and accessible both to professors and assessment agents and to students:
Milestones, actions, skills, descriptors to be assessed for each action, level
of expected achievement and the assessment reports, etc. The students must
find out the results given by each of the evaluators as soon as possible so
that these can guide the work that they have yet to do. CONCLUSIONS The User
Guide that has been developed provides an efficient and objective mechanism
for the assessment of FYP. It is a flexible instrument that each centre must
personalise in accordance with their objectives. The Assessment Guide
resulting from this personalisation will help increase the homogeneity of
qualifications, the traceability of results, and the general quality of the
process of assessing FYP. ACKNOWLEDGMENT One of the problems with working in
teams is honouring the valuable input made by of all of the members without
the list being seemingly never-ending. We have included six authors in the
report, but there were many, many more: Components of the AQU-MICINN project
Elena Valderrama (UAB), Jesús Bisbal (UPF), Julián Carrera (UAB), Francesc
Castells (URV), Fernando Cores (UdL), Jordi García (UPC), Laureano Jiménez
(URV), Claudi Mans (UB), Tomàs Margalef (UAB), Asunción Moreno (UPC), Enric
Peig (UPF), Julio Pérez (UAB), Jordi Pons (UAB), Mercè Rullán (UAB), Fermín
Sánchez (UPC), Gonzalo Seco (UAB), Joan Sorribes (UAB), Javier Tejero (UB),
Ramón Vilanova (UAB). Thank you to all of them. REFERENCES [1] AQU (Agència
per a la qualitat del sistema universitari a Catalunya). Guia per a
l’avaluació de competències en els Treballs Fi d’Estudis a les Enginyeries.
2009. In press. [2] Complete Set Dublin Descriptors 2004.
http://www.jointquality.org/. Last access, February 2009. [3] NCES. Defining
and Assessing Learning: Exploring Competency-Based Initiatives. 2002\.
Electronic version accessible at: http://nces.ed.gov/pubs2002/2002159.pdf Last
access February 2009. [4] Tuning Project. Una introducción a Tuning
Educational Structures in Europe.. Electronic version accessible at:
http://tuning.unideusto.org/tuningeu/images/stories/template/General_Bro
chure_Spanish_version.pdf. Last access, February 2009. [5] Sánchez F. et al.
Competencias profesionales del Grado en Ingeniería Informática. JENUI 2008.
[6] Villa, A; Poblete, M. Aprendizaje basado en competencias. Ed Mensajero.
Universidad de Deusto. 2007 [7] Voorthess, R. Measuring what matters:
competency-based learning models. Higher Education. Jossey Bass. 2001 AUTHOR
INFORMATION Elena Valderrama, Autonoma University of Barcelona.
Elena.Valderrama@uab.cat Mercè Rullán, Autonoma University of Barcelona.
Mercedes.Rullan@uab.cat Fermín Sánchez, Technical University of Catalonia.
Fermin@ac.upc.edu Jordi Pons, Autonoma University of Barcelona.
Jordi.Pons@uab.cat Claudi Mans, University of Barcelona. cmans@ub.edu Francesc
Giné, University of Lleida. sisco@diei.udl.cat Laureà Jiménez, Rovira Virgili
University. Laureano.Jimenez@urv.cat Enric Peig, Pompeu Fabra University.
enric.peig@upf.edu

